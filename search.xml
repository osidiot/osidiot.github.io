<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>PCIe Posted Vs Non-Posted Transactions</title>
      <link href="/pci-non-post.html"/>
      <url>/pci-non-post.html</url>
      
        <content type="html"><![CDATA[<p>在<a href="../virtio.0.95-reset.html">硬件virtio 0.95 reset问题</a>中提到了PCIe <strong>posted transactions</strong>和<strong>non-posted transactions</strong>两个概念，当时未做细致的分析，此处进行适量补充。学习输入也仅仅是些外网博客，讲得比较肤浅不够权威，但对于目前我的工作内容来说基本足够了。</p><h4 id="Non-posted-Transactions"><a href="#Non-posted-Transactions" class="headerlink" title="Non-posted Transactions"></a>Non-posted Transactions</h4><p>当设备完成请求处理后，需要向requester发送一个completion Transaction Layer Packet (TLP) 。Completer可以在收到请求后的某个时刻发送TLP完成报文，可以不必立刻回复。</p><p>对于读操作，完成报文中包含了读取到的数据（如果成功）或者error status（如果失败）；对于写操作，完成报文中不会含有数据（如果成功）、但可能包含error status（如果失败）。</p><p>以CPU为requester为例：</p><p><img src="/images/CPU_mem_rd.png"></p><p>&nbsp;</p><h4 id="Posted-Transactions"><a href="#Posted-Transactions" class="headerlink" title="Posted Transactions"></a>Posted Transactions</h4><p>Requester不希望、也不会收到TLP完成报文。如果发生失败，requester将不会知道，但是completer可以触发失败消息通知到Root Complex。</p><p>以CPU为requester为例：</p><p><img src="/images/CPU_mem_wr.png"></p><p>&nbsp;</p><h4 id="差异总结"><a href="#差异总结" class="headerlink" title="差异总结"></a>差异总结</h4><p>If we compare the life cycle of a bus write operation with the one of a read, there’s an evident difference:</p><ul><li>A <strong>write</strong> TLP operation is <strong>fire-and-forget</strong>. Once the packet has been formed and handed over to the Data Link Layer, there’s no need to worry about it anymore.</li><li>A <strong>read</strong> operation, on the other hand, requires the Requester to wait for a Completion. Until the Completion packet arrives, the Requester must retain information about what the Request was, and sometimes even hold the CPU’s bus: If the CPU’s bus started a read cycle, it must be held in wait states until the value of the desired read operation is available at the bus’ data lines. This can be a horrible slowdown of the bus, which is rightfully avoided in recent systems.</li></ul><p>&nbsp;</p><h4 id="典型操作分类"><a href="#典型操作分类" class="headerlink" title="典型操作分类"></a>典型操作分类</h4><table><thead><tr><th>Non-posted Transcations</th><th>Posted Transactions</th></tr></thead><tbody><tr><td>Memory Reads<br />Memory Read Lock<br />I/O Reads<br />I/O Writes<br />Configuration Reads (both Type 0 and Type 1)<br />Configuration Writes (both Type 0 and Type 1)</td><td>Memory Writes<br />Messages</td></tr></tbody></table><p>&nbsp;</p><h4 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h4><ol><li><a href="http://xillybus.com/tutorials/pci-express-tlp-pcie-primer-tutorial-guide-1">http://xillybus.com/tutorials/pci-express-tlp-pcie-primer-tutorial-guide-1</a></li><li><a href="https://paritycheck.wordpress.com/2008/01/13/pcie-posted-vs-non-posted-transactions/">https://paritycheck.wordpress.com/2008/01/13/pcie-posted-vs-non-posted-transactions/</a></li><li>《<em>PCI</em> <em>Express</em> <em>System</em> <em>Architecture</em>》</li></ol>]]></content>
      
      
      <categories>
          
          <category> 体系结构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> virtio </tag>
            
            <tag> pcie </tag>
            
            <tag> 体系结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Virtio硬件实现——0.95 reset问题</title>
      <link href="/virtio.0.95-reset.html"/>
      <url>/virtio.0.95-reset.html</url>
      
        <content type="html"><![CDATA[<h3 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h3><p>最近，在讨论如何在mlnx硬件卸载场景上支持virtio 0.95，因为virtio 0.95协议本身对硬件virtio直通不够友好，所以需要做些特殊的quirks处理。</p><p>面临最棘手的问题便是：virtio 0.95规范中对STATUS寄存器没有约定需同步等待，导致某些较老版本的virtio legacy驱动无法支持。举例来说：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">vp_reset</span><span class="params">(struct virtio_device *vdev)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">virtio_pci_device</span> *<span class="title">vp_dev</span> =</span> to_vp_device(vdev);</span><br><span class="line"><span class="comment">/* 0 status means a reset. */</span></span><br><span class="line">iowrite8(<span class="number">0</span>, vp_dev-&gt;ioaddr + VIRTIO_PCI_STATUS);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述为Linux 2.6.39中virtio legacy驱动的实现，可见：<strong>在reset设备时，将STATUS清零后直接返回</strong>。</p><p>在QEMU模拟virtio场景下，此方式无问题，因为iowrite将引起陷出，最终由QEMU进行相应reset操作。</p><p>但是在硬件virtio VF直通场景下，cpu下发完reset请求后，VF硬件可能还没有处理完成，cpu便可继续执行后续操作，这便存在潜在风险：后续操作的正确性可能依赖于VF硬件已经reset完成，而彼时VF硬件可能尚在reset过程中（e.g. <strong>后续运行过程中读取STATUS时，可能STATUS寄存器依然不为零</strong>）。</p><p>&nbsp;</p><h3 id="关键分析"><a href="#关键分析" class="headerlink" title="关键分析"></a>关键分析</h3><h4 id="cpu通过iowrite操作PCIe设备能否阻塞cpu？"><a href="#cpu通过iowrite操作PCIe设备能否阻塞cpu？" class="headerlink" title="cpu通过iowrite操作PCIe设备能否阻塞cpu？"></a>cpu通过iowrite操作PCIe设备能否阻塞cpu？</h4><p>在linux内核中，iowrite实际上有pio、mmio两种具体实现方式，首先需要明白我们场景中使用的是哪一种！</p><p>我们通过SR-IOV + vfio-pci直通方式将virtio VF直通给虚拟机，SR-IOV规范有个限制：<strong>VF只支持memory BAR、不支持io BAR，因此对其访问只能是以mmio方式</strong>。</p><p>说下答案：<strong>不能!!!!</strong></p><p>如果mmio能够阻塞就好了，就能够在设备reset完成后再让cpu继续执行下去，我们就不会遇到上面的问题了。</p><p>那么，为什么不能呢？</p><p>mmio write属于“Memory write”操作。在PCIe体系中，Memory write属于<strong>Posted Transactions</strong>，requester（此处即cpu）不需要等待completion TLP，可以立刻去干别的事情，类似导弹技术中的“发射后不管”。</p><p>&nbsp;</p><h4 id="较新的virtio-legacy驱动是否有同步？"><a href="#较新的virtio-legacy驱动是否有同步？" class="headerlink" title="较新的virtio legacy驱动是否有同步？"></a>较新的virtio legacy驱动是否有同步？</h4><p>来看一下Linux 5.12中virtio legacy驱动的相关实现：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">vp_reset</span><span class="params">(struct virtio_device *vdev)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">virtio_pci_device</span> *<span class="title">vp_dev</span> =</span> to_vp_device(vdev);</span><br><span class="line"><span class="comment">/* 0 status means a reset. */</span></span><br><span class="line">iowrite8(<span class="number">0</span>, vp_dev-&gt;ioaddr + VIRTIO_PCI_STATUS);</span><br><span class="line"><span class="comment">/* Flush out the status write, and flush in device writes,</span></span><br><span class="line"><span class="comment"> * including MSi-X interrupts, if any. */</span></span><br><span class="line">ioread8(vp_dev-&gt;ioaddr + VIRTIO_PCI_STATUS);</span><br><span class="line"><span class="comment">/* Flush pending VQ/configuration callbacks. */</span></span><br><span class="line">vp_synchronize_vectors(vdev);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们可以看到：在reset之后，多了一个ioread的动作。根据注释，此处ioread的原因并不是为了和底层硬件进行同步，而仅仅是为了确保上面的iowrite操作能够flush out或者设备的写操作能够flush in，主要是站在cpu角度进行内存屏障之类的处理。</p><p>但是，<strong>这却为硬件virtio 0.95实现创造了一个机会，可以利用ioread做文章</strong>。</p><p>ioread在我们分析的场景中是mmio read，属于“Memory read”操作，此类请求属于<strong>Non-posted Transactions</strong>，意味着requester（此处即cpu）需要等待PCIe硬件回复completion TLP方可继续。如此一来，便可以借机实现“伪同步”的效果：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sequenceDiagram</span><br><span class="line">    cpu -&gt;&gt; + Virtio VF : iowrite STATUS-&gt;0</span><br><span class="line">    Virtio VF -&gt;&gt; Virtio VF : starting reset</span><br><span class="line">    cpu -&gt;&gt; + Virtio VF : ioread STATUS</span><br><span class="line">    cpu -&gt;&gt; cpu : wait for Read completion TLP</span><br><span class="line">    Virtio VF -&gt;&gt; Virtio VF : finish reset</span><br><span class="line">    Virtio VF -&gt;&gt;  cpu : reply Read completion TLP</span><br><span class="line">    cpu -&gt;&gt; cpu : continue</span><br></pre></td></tr></table></figure><p>可以看到：只要Virtio VF硬件中控制好在reset处理完成后才能处理后续请求（即读请求），便能够实现“同步”的效果。</p><p>&nbsp;</p><h4 id="virtio-modern驱动能够实现同步？"><a href="#virtio-modern驱动能够实现同步？" class="headerlink" title="virtio modern驱动能够实现同步？"></a>virtio modern驱动能够实现同步？</h4><p>来看一下Linux 5.12中virtio modern（ &gt;= virtio 1.0）驱动的实现：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">vp_reset</span><span class="params">(struct virtio_device *vdev)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">virtio_pci_device</span> *<span class="title">vp_dev</span> =</span> to_vp_device(vdev);</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">virtio_pci_modern_device</span> *<span class="title">mdev</span> =</span> &amp;vp_dev-&gt;mdev;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 0 status means a reset. */</span></span><br><span class="line">vp_modern_set_status(mdev, <span class="number">0</span>);</span><br><span class="line"><span class="comment">/* After writing 0 to device_status, the driver MUST wait for a read of</span></span><br><span class="line"><span class="comment"> * device_status to return 0 before reinitializing the device.</span></span><br><span class="line"><span class="comment"> * This will flush out the status write, and flush in device writes,</span></span><br><span class="line"><span class="comment"> * including MSI-X interrupts, if any.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">while</span> (vp_modern_get_status(mdev))</span><br><span class="line">msleep(<span class="number">1</span>);</span><br><span class="line"><span class="comment">/* Flush pending VQ/configuration callbacks. */</span></span><br><span class="line">vp_synchronize_vectors(vdev);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * vp_modern_get_status - get the device status</span></span><br><span class="line"><span class="comment"> * @mdev: the modern virtio-pci device</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Returns the status read from device</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function">u8 <span class="title">vp_modern_get_status</span><span class="params">(struct virtio_pci_modern_device *mdev)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">virtio_pci_common_cfg</span> __<span class="title">iomem</span> *<span class="title">cfg</span> =</span> mdev-&gt;common;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> vp_ioread8(&amp;cfg-&gt;device_status);</span><br><span class="line">&#125;</span><br><span class="line">EXPORT_SYMBOL_GPL(vp_modern_get_status);</span><br></pre></td></tr></table></figure><p>可以看到：驱动将主动等待STATUS变为0。<strong>当然，Virtio设备需要在reset操作处理完成后，才将STATUS复位成0</strong>。</p><p>个人认为，此种驱动实现方式对硬件（virtio VF、cpu）更加友好：</p><ul><li>“较新的virtio legacy驱动”需要Virtio VF硬件中实现：read STATUS操作需要等到reset操作结束后才能回复completion TLP，增加了硬件内部实现的复杂度；而“virtio modern驱动”不需要VF硬件做类似保障，reset操作与read STATUS操作是解耦的，无内在牵连。</li><li>如果reset操作耗时较久，“较新的virtio legacy驱动”将导致cpu一直处于等待read STATUS响应的状态；而“virtio modern驱动”可以通过msleep主动触发任务调度。</li></ul><p>&nbsp;</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>（<strong>注意：我们描述的是virtio硬化的问题，虚机场景是指通过vfio-pci直通给VM的使用场景</strong>）</p><table><thead><tr><th align="left">驱动</th><th>支持裸机</th><th>支持虚机</th><th>支持同步</th><th>硬件复杂度<br />（为支持同步）</th></tr></thead><tbody><tr><td align="left">较老的legacy virtio 0.95驱动</td><td>N</td><td>N：直通无特殊处理<br />Y-：直通，但QEMU quirk BAR然后同步等待</td><td>N</td><td>-</td></tr><tr><td align="left">较新的legacy virtio 0.95驱动</td><td>Y-</td><td>Y-</td><td>Y-</td><td>High</td></tr><tr><td align="left">modern virtio 1.0/1.1驱动</td><td>Y</td><td>Y</td><td>Y</td><td>Low</td></tr></tbody></table><p>&nbsp;</p><ul><li><p>较老的legacy驱动</p><ul><li>不支持裸机，目前无任何办法</li><li>对虚机的支持需要hypervisor辅助：<ul><li>不辅助的话无法支持</li><li>辅助方式：截获virtio BAR的访问，对于STATUS clear需实现等待机制</li></ul></li><li>不支持reset同步</li></ul></li><li><p>较新的legacy驱动</p><ul><li>支持裸机，在read STATUS回复时需要保证STATUS clear已完成</li><li>支持虚机：<ul><li>截获virtio BAR的访问，对于STATUS clear需实现等待机制</li><li>无需截获，由硬件保证“在read STATUS回复时需要保证STATUS clear已完”。此种场景下关键的问题是：hypervisor本身感知不到guest内部所用驱动的版本，如何确定是否需要截获？</li></ul></li><li>支持reset同步：<ul><li>个人称之为“伪同步”，最终能达到同步的效果，只能说是“误打误撞”，驱动的行为刚好可以被利用</li></ul></li><li>因reset同步，硬件实现复杂度高</li></ul></li><li><p>modern驱动</p><ul><li>比较合理的驱动/协议实现，是最合理的解决方案。这得益于随着硬件virtio普及，virtio社区与时俱进的更新。</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> virtio </category>
          
      </categories>
      
      
        <tags>
            
            <tag> virtio </tag>
            
            <tag> pcie </tag>
            
            <tag> 体系结构 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
